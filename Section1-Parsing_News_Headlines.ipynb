{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import geonamescache\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "\n",
    "gc = geonamescache.GeonamesCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headlines\n",
    "\n",
    "The first thing we'll do is read in the headlines we'll be examining. We'll be cleaning them up by removing trailing whitespace and converting from Unicode to ASCII for ease-of-processing later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/headlines.txt\") as headline_file:\n",
    "    # Remove any unnecessary leading whitespace for consistency\n",
    "    headlines = [ unidecode(line.strip()) for line in headline_file ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "We have to determine the country and/or city in any given headline (if there is one!). We'll do that by creating many Regular Expressions based on each city/country that we'll use to parse each headline later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = gc.get_countries_by_names().keys()\n",
    "# Pad the country regex string with word boundary meta-characters to avoid false matches\n",
    "country_regex_strgen = (r\"\\b{}\\b\".format(unidecode(country)) for country in countries)\n",
    "country_regexes = [re.compile(country, re.ASCII) for country in country_regex_strgen]\n",
    "\n",
    "cities = gc.get_cities()\n",
    "# Same as the country regex strings, add word boundary meta-characters\n",
    "city_regex_strgen = (r\"\\b{}\\b\".format(unidecode(cities[id]['name'])) for id in cities.keys())\n",
    "city_regexes = [re.compile(city, re.ASCII) for city in city_regex_strgen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex: Longest Match\n",
    "\n",
    "If location names are similar, we may get multiple matches. We want to filter through these to ensure we're finding the correct location. We'll do this by only choosing the longest matching string.\n",
    "\n",
    "e.g. If we have the headline \"Zika confirmed in Miami Beach\", the regexes for \"Miami\" and \"Miami Beach\" will both match, but since \"Miami Beach\" is longer, we'll associate the headline with Miami beach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_match(regex_list, line):\n",
    "    longest_match = \"\"\n",
    "    for regex in regex_list:\n",
    "        result = regex.search(line)\n",
    "        if result:\n",
    "            if len(result.group(0)) > len(longest_match):\n",
    "                longest_match = result.group(0)\n",
    "    # Return None only if we have an empty string\n",
    "    return longest_match if longest_match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(headline=[], country=[], city=[])\n",
    "for headline in headlines:\n",
    "    data['headline'].append(headline)\n",
    "    data['country'].append(find_longest_match(country_regexes, headline))\n",
    "    data['city'].append(find_longest_match(city_regexes, headline))\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
