{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading updated headlines from file\n",
    "\n",
    "To speed data processing up for later, we'll read in our freshly-processed headlines with Latitude, Longitude, and Country Code from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"data/headlines_augmented.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing before Clustering\n",
    "\n",
    "First, we'll try just looking at our data and make sure our data makes sense. From here, we can try \"eyeballing\" some values for k-mean clustering and DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "import math\n",
    "\n",
    "map_plotter = Basemap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long_pairs = df[['latitude', 'longitude']].to_numpy()\n",
    "latitudes, longitudes = lat_long_pairs.T\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "map_plotter.scatter(longitudes, latitudes, latlon=True)\n",
    "map_plotter.shadedrelief()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing: K-Mean Elbow Plotting\n",
    "\n",
    "Since there are many reasonably-sized centers of points, we'll try elbow plotting to figure out a reasonable k-value. \n",
    "\n",
    "kâ‰¥6 may be a good first guess, since there are 6 continents with points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = range(1, 21)\n",
    "inertia_values = [KMeans(n_clusters=i).fit(lat_long_pairs).inertia_ for i in k_values]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(k_values, inertia_values)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.show()\n",
    "for i, v in enumerate(inertia_values, start=1):\n",
    "    print(f\"{i}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering: K-Means\n",
    "\n",
    "Since 5 is the last \"elbow\" in the curve, it looks like a guess of 6 wasn't a bad start. We'll still try 6 as our k-value, and create a DataFrame with this number of clusters in mind. However, this may not prove optimal since we're interested in dense outbreak regions rather than outbreak regions with a certain center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/questions/14720331/how-to-generate-random-colors-in-matplotlib\n",
    "# Used for colormapping more than 10 colors, to prevent\n",
    "# different clusters in close proximity from causing confusion when drawn\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 16\n",
    "clusters = KMeans(n_clusters=NUM_CLUSTERS).fit_predict(lat_long_pairs)\n",
    "df_kmean = df.copy()\n",
    "df_kmean['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "cluster_group = df_kmean.groupby('cluster')\n",
    "cmap = get_cmap(len(cluster_group))\n",
    "for cluster_id, cluster in cluster_group:\n",
    "    if cluster_id == -1: continue\n",
    "    map_plotter.scatter(cluster.longitude, cluster.latitude, latlon=True, color=cmap(cluster_id))\n",
    "    \n",
    "map_plotter.shadedrelief()\n",
    "plt.legend( [f\"Cluster {cid}\" for cid, _ in cluster_group if cid != -1], \\\n",
    "               loc=\"lower left\", markerscale=2, fontsize=\"medium\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while at first glance this map looks fine (k=6), there are some obvious problems (e.g. Pacific Asia and Australia are one cluster) that indicate we have to change some parameters. In this case, we'll add more than 6 clusters.\n",
    "\n",
    "After further experimentation based on the interia values calculated above, k=16 seems to be a reasonable number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering: DBSCAN\n",
    "\n",
    "Since we're trying to locate clusters of regions based on the proximity of other cities in distress, it may be a good idea to do density-based clustering, since certain regions may be more dense than others and require a limiting of resources, or require more resources to cover a larger area, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the Haversine formula, found here: https://www.movable-type.co.uk/scripts/latlong.html\n",
    "def great_circle(point_1, point_2):\n",
    "    RADIUS = 6371  # Kilometers, Earth's mean radius\n",
    "    lat_1 = math.radians(point_1[0])\n",
    "    lat_2 = math.radians(point_2[0])\n",
    "    d_lat = lat_2 - lat_1\n",
    "    d_long = math.radians(point_2[1] - point_1[1])\n",
    "    a = math.sin(d_lat/2) * math.sin(d_lat/2) + math.cos(lat_1) \\\n",
    "            * math.cos(lat_2) * math.sin(d_long/2) * math.sin(d_long/2)\n",
    "    c = 2 * math.atan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    return RADIUS * c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll run the DBSCAN procedure and create an augmented DataFrame with the new clusters. The values for `MAX_KM` and `MIN_LOC` were experimentally determined, the process and code I used can be found under the **DBSCAN: Experimentation** heading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_KM = 500  # 403km is about 250 miles\n",
    "MIN_LOC = 3\n",
    "clusters = DBSCAN(eps=MAX_KM, min_samples=MIN_LOC, metric=great_circle).fit_predict(lat_long_pairs)\n",
    "df_dbscan = df.copy()\n",
    "df_dbscan['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll plot our results and see if we should change some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_group = df_dbscan.groupby('cluster')\n",
    "plt.figure(figsize=(20, 12))\n",
    "cmap = get_cmap(len(cluster_group))\n",
    "for cluster_id, cluster in cluster_group:\n",
    "    if cluster_id == -1: continue\n",
    "    map_plotter.scatter(cluster.longitude, cluster.latitude, latlon=True, color=cmap(cluster_id))\n",
    "    \n",
    "map_plotter.shadedrelief()\n",
    "plt.legend( [f\"Cluster {cid}\" for cid, _ in cluster_group if cid != -1], \\\n",
    "               loc=\"lower left\", markerscale=2, fontsize=\"medium\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I find this clustering to be insufficient later on, it should be fairly easy to modify its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN: Experimentation\n",
    "\n",
    "Since I don't have any experience with DBSCAN (or data clustering in general), I decided to do some experimentation with DBSCAN's `eps` and `min_samples` parameters to get a feeling for how both of these parameters would affect the result. The cell has been converted to a \"raw\" cell to prevent execution, and remains here merely to document my thought process.\n",
    "\n",
    "### `eps` tuning\n",
    "As the maximum distance between each point/city increased, I found that the number of clusters had decreased -- for example, several US clusters had merged into one large cluster when going from 400km to 500km. This did not affect other countries as much in terms of cluster size. However, it did begin to include otherwise far-away cities to add to each cluster. This could potentially add noise to each cluster, so I made sure not to go too high in terms of distance.\n",
    "\n",
    "I eventually decided that the best `eps` value would be in the range 400-550, since beyond that and it begins to include too many far cities into one cluster and ruined the \"centrality\" of each. I eventually settled on **500km** as it didn't ignore smaller clusters of cities (for example, some cities in South America) while also not spreading out each point in the cluster too far.\n",
    "### `min_samples` tuning\n",
    "I started with 3, 4, 5, and 6 as possible numbers of minimum cities per cluster, but quickly found that 5 and 6 were removing too many data points. While they made each cluster more \"significant\" by having only larger (and potentially more at risk) areas, they excluded some smaller areas that may require examination. 4 seemed like a reasonable compromise, but still eliminated some clusters that I felt should remain (e.g. Malaysia was removed with a 4 city minimum)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Brute force experimentation to get a hang of DBSCAN\n",
    "from itertools import product\n",
    "km_vars = [400, 450, 500, 550, 600, 650]\n",
    "city_vars = [3, 4]\n",
    "for _MAX_KM, MIN_LOCATION in product(km_vars, city_vars):\n",
    "    clusters = DBSCAN(eps=_MAX_KM, min_samples=MIN_LOCATION, metric=great_circle).fit_predict(lat_long_pairs)\n",
    "    df_dbscan = df.copy()\n",
    "    df_dbscan['cluster'] = clusters\n",
    "    NUM_CLUSTERS = df_dbscan.cluster.max()\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    cmap = get_cmap(len(df_dbscan.groupby('cluster')))\n",
    "    for cluster_id, cluster in df_dbscan.groupby('cluster'):\n",
    "        if cluster_id == -1: continue\n",
    "        map_plotter.scatter(cluster.longitude, cluster.latitude, latlon=True, color=cmap(cluster_id))\n",
    "    \n",
    "    map_plotter.drawcoastlines()\n",
    "    map_plotter.drawcountries()\n",
    "    plt.legend( [f\"Cluster {i}\" for i in range(1, NUM_CLUSTERS+1)], \\\n",
    "               loc=\"lower left\", markerscale=2, fontsize=\"medium\" )\n",
    "    plt.savefig(f\"dbscan_km{_MAX_KM}_city{MIN_LOCATION}.png\", dpi=300, orientation=\"landscape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN: Euclidean Clustering (after the fact)\n",
    "\n",
    "**Note**: This section was added after looking at the solution, and was not done during my initial experimentation with DBSCAN. The only metric I had used then was the great circle distance. This is mainly to \"play around\" with the euclidean metric, since I didn't think to do that originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclid_clusters = DBSCAN(eps=9, min_samples=3).fit_predict(lat_long_pairs)\n",
    "df_euclid_dbscan = df.copy()\n",
    "df_euclid_dbscan['cluster'] = euclid_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "cluster_group = df_euclid_dbscan.groupby('cluster')\n",
    "for cluster_id, cluster in cluster_group:\n",
    "    if cluster_id == -1: continue\n",
    "    map_plotter.scatter(cluster.longitude, cluster.latitude, latlon=True)\n",
    "map_plotter.shadedrelief()\n",
    "#map_plotter.drawcoastlines()\n",
    "#map_plotter.drawcountries()\n",
    "plt.legend( [f\"Cluster {cid}\" for cid, _ in cluster_group if cid != -1], \\\n",
    "                loc=\"lower left\", markerscale=2, fontsize=\"medium\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_euclid_dbscan.to_csv(\"data/clustered_headlines.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
